{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from AE_Functions import *\n",
    "from pandas import *\n",
    "from io import BytesIO\n",
    "import time\n",
    "import sys\n",
    "from forex_python.converter import CurrencyRates\n",
    "from scipy.optimize import minimize\n",
    "#import pyfolio\n",
    "import numpy as np\n",
    "#from nbconvert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "def GeoMeanReturn(pct_change_column):\n",
    "    return (((1 + pct_change_column).product()) ** (1 / (len(pct_change_column))) - 1) * 12\n",
    "\n",
    "def ret(returns, weights):\n",
    "    return returns.dot(weights)\n",
    "\n",
    "def pf_var(covar,weights):\n",
    "    return np.dot(weights,np.dot(weights,covar))\n",
    "\n",
    "def pf_vol(covar,weights):\n",
    "    return np.sqrt(np.dot(weights,np.dot(weights,covar)))\n",
    "\n",
    "def get_ret_vol_sr(weights):\n",
    "    weights = np.array(weights)\n",
    "    #ret = np.sum(log_ret.mean() * weights) * 12\n",
    "    ret = np.sum(GeoMeanReturn(log_ret) * weights)\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 12, weights)))\n",
    "    sr = ret / vol\n",
    "    return np.array([ret, vol, sr])\n",
    "\n",
    "\n",
    "def neg_sharpe(weights):\n",
    "    return get_ret_vol_sr(weights)[2] * -1\n",
    "\n",
    "\n",
    "def constraint_check_sum(weights):\n",
    "    return np.sum(weights) - 1\n",
    "\n",
    "def constraint_vola(weights, Vola):\n",
    "    return get_ret_vol_sr(weights)[1]\n",
    "\n",
    "def minimize_volatility(weights):\n",
    "    return get_ret_vol_sr(weights)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel('Input.xlsx')\n",
    "\n",
    "beg=(2010,1,1)\n",
    "end=(2022,12,31)\n",
    "\n",
    "ticker = (df['Ticker'].values)\n",
    "col_names = (df['Name'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lyxor MSCI World (LUX) UCITS ETF',\n",
       "       'Vanguard FTSE Developed Europe UCITS ETF',\n",
       "       'Deka iBoxx EUR Liquid Corps Diversified',\n",
       "       'Deka iBoxx EUR Liquid Sovereign Diversified 5-7',\n",
       "       'Xtrackers II ESG Global Aggregate Bond UCITS ETF'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten werden heruntergeladen und aufbereitet....\n",
      "Error:  module 'yfinance' has no attribute 'pdr_override'\n",
      "Security:  X010.DE\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     quotes\u001b[38;5;241m.\u001b[39minsert(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(quotes\u001b[38;5;241m.\u001b[39mcolumns), column\u001b[38;5;241m=\u001b[39mi, value\u001b[38;5;241m=\u001b[39m\u001b[43mgetQuote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     tmp_min_dates\u001b[38;5;241m=\u001b[39mquotes\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Persönlich/Programmieren/Python/Selfmade/FinaLytics/AE_Functions.py:102\u001b[0m, in \u001b[0;36mgetQuote\u001b[0;34m(ticker, BegDt, EndDt, interval)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdr_override\u001b[49m()\n\u001b[1;32m    104\u001b[0m start_year, start_month, start_day \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, BegDt)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'yfinance' has no attribute 'pdr_override'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSecurity: \u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n\u001b[0;32m---> 23\u001b[0m         \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaten verfügbar....\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "# -------------Tab Data---------------------------\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "quotes = pd.DataFrame()\n",
    "tmp_min_dates = pd.DataFrame()\n",
    "min_dates=[]\n",
    "\n",
    "print('Daten werden heruntergeladen und aufbereitet....')\n",
    "\n",
    "for i in ticker:\n",
    "    try:\n",
    "\n",
    "        quotes.insert(loc=len(quotes.columns), column=i, value=getQuote(i, beg, end, '1d'))\n",
    "        tmp_min_dates=quotes\n",
    "        min_dates.append(tmp_min_dates.index.min().to_pydatetime().date())\n",
    "        quotes.dropna(inplace=True)\n",
    "        # monthly_quotes=quotes.resample('M').agg(lambda x: x[-1])\n",
    "        monthly_quotes_ForCCY = quotes.resample('BM').last()\n",
    "    except Exception as err:\n",
    "        print('Error: ', err)\n",
    "        print('Security: ', i)\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "print('Daten verfügbar....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- Download Währungen --------------------------------\n",
    "from currency_converter import CurrencyConverter\n",
    "from datetime import timedelta\n",
    "currencies = df['Currency'].drop_duplicates()\n",
    "c = CurrencyConverter()\n",
    "df_CCY = pd.DataFrame()\n",
    "for ccy in currencies:\n",
    "    fx_rates = []\n",
    "    for day in monthly_quotes_ForCCY.index.date:\n",
    "        try:\n",
    "            x = c.convert(1,'EUR',ccy,day)\n",
    "            fx_rates.append(x)\n",
    "        except:\n",
    "            dayminusone=day-timedelta(days=1)\n",
    "            x = c.convert(1,'EUR',ccy,dayminusone)\n",
    "            fx_rates.append(x)\n",
    "            continue\n",
    "    fx_rates_ = pd.Series(fx_rates, index=monthly_quotes_ForCCY.index.date)\n",
    "    df_CCY.insert(loc=len(df_CCY.columns),column=ccy,value=fx_rates)\n",
    "\n",
    "df_CCY.index=monthly_quotes_ForCCY.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Calculate Domestic Return ----------------------\n",
    "monthly_quotes = pd.DataFrame()\n",
    "monthly_quotes_data = monthly_quotes_ForCCY.join(df_CCY,how='outer')\n",
    "for i in ticker:\n",
    "    ccy = (df.loc[df['Ticker']==i,['Currency']].values)[0][0]\n",
    "    monthly_quotes[str(i)] = monthly_quotes_data[i]/monthly_quotes_data[ccy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------Tab Assets----------------\n",
    "\n",
    "print('Worksheet Assets wird vorbereitet....')\n",
    "\n",
    "#Performance = monthly_quotes.pct_change().dropna()\n",
    "Performance = np.log(monthly_quotes/monthly_quotes.shift(1)).dropna()\n",
    "#MeanReturn = (((1 + Performance).product()) ** (1 / (len(Performance) - 1)) - 1) * 12\n",
    "MeanReturn = GeoMeanReturn(Performance)\n",
    "vola = Performance.std() * np.sqrt(12)\n",
    "cov = Performance.cov() * 12\n",
    "\n",
    "\n",
    "\n",
    "list_ret = []\n",
    "vol = []\n",
    "\n",
    "for i in MeanReturn.values:\n",
    "    list_ret.append(i)\n",
    "\n",
    "for i in vola.values:\n",
    "    vol.append(i)\n",
    "\n",
    "weights = df['Wert in EUR/Sparrate'] / df['Wert in EUR/Sparrate'].sum()\n",
    "\n",
    "df.insert(loc=6, column='Weights', value=weights)\n",
    "df.insert(loc=7, column='Return', value=list_ret)\n",
    "df.insert(loc=8, column='Standard Deviation', value=vol)\n",
    "df.insert(loc=9, column='Sharpe Ratio [ohne Berücksichtigung von rf]',\n",
    "        value=df['Return'] / df['Standard Deviation'])\n",
    "df.insert(loc=10, column='Earliest Datapoint', value=min_dates)\n",
    "\n",
    "df_MyPortfolio = monthly_quotes\n",
    "df_MyPortfolio_returns = np.log(monthly_quotes/monthly_quotes.shift(1)).dropna()\n",
    "#df_MyPortfolio_returns = df_MyPortfolio.pct_change().dropna()\n",
    "\n",
    "#df_MyPortfolio.insert(loc=0,column=col_names, value=quotes)\n",
    "#print(df_MyPortfolio_returns)\n",
    "\n",
    "for i,w in enumerate(weights):\n",
    "    df_MyPortfolio_returns.iloc[:,i] = df_MyPortfolio_returns.iloc[:,i] * w\n",
    "\n",
    "    \n",
    "df_MyPortfolio_returns.insert(loc=0,column='CompositeReturn',value=df_MyPortfolio_returns.sum(axis=1))\n",
    "\n",
    "\n",
    "for i,w in enumerate(weights):\n",
    "    df_MyPortfolio_returns.iloc[:,i+1] = df_MyPortfolio_returns.iloc[:,i+1] / w\n",
    "\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------Correlation Matrix------\n",
    "print('Worksheet Correlation Matrix wird vorbereitet....')\n",
    "\n",
    "df_corr = pd.DataFrame()\n",
    "df_cov = pd.DataFrame()\n",
    "dummy_df = pd.DataFrame()\n",
    "\n",
    "for i in ticker:\n",
    "    try:\n",
    "        price = getQuote(i, beg, end, '1d')\n",
    "        price = price.ffill()\n",
    "        monthly_prices = price.resample('BM').last()  # filtert den letzten Tag im Monat // BM = Business Month // Alternative: 1ter Tag im Monat ('BMS').first() // BMS = Business Month Start\n",
    "        #perf = monthly_prices.pct_change()\n",
    "        perf = np.log(monthly_prices/monthly_prices.shift(1))\n",
    "        df_corr.insert(loc=len(df_corr.columns), column=i, value=perf)\n",
    "        df_cov.insert(loc=len(df_cov.columns), column=i, value=perf)\n",
    "    except Exception as err:\n",
    "        print('Error: ', err)\n",
    "        print('Security: ', i)\n",
    "        sys.exit(0)\n",
    "\n",
    "df_corr.columns = col_names\n",
    "\n",
    "df_corr.dropna(inplace=True)\n",
    "df_corr = df_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------Tab Portfolio Statistics-------------\n",
    "print('Worksheet Portfolio Statistics wird vorbereitet....')\n",
    "\n",
    "##------------Expected Return----------\n",
    "\n",
    "\n",
    "#Exp = df['Return'] * df['Weights']\n",
    "#Exp = Exp.sum()\n",
    "#Exp = ret(df['Return'].fillna(0),df['Weights'])\n",
    "Exp = ret(df['Return'],df['Weights'])\n",
    "\n",
    "\n",
    "\n",
    "##------------Standard Deviation-------\n",
    "\n",
    "df_cov.columns = col_names\n",
    "df_cov.dropna(inplace=True)\n",
    "df_cov = df_cov.cov() * 12\n",
    "\n",
    "#port_var = np.dot(df['Weights'].T, np.dot(df_cov, df['Weights']))\n",
    "#port_vol = np.sqrt(port_var)\n",
    "\n",
    "port_vol = pf_vol(df_cov,df['Weights'].T)\n",
    "port_var = pf_var(df_cov,df['Weights'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Efficient Frontier---------------------------\n",
    "print('Efficient Frontier wird vorbereitet....')\n",
    "\n",
    "\n",
    "log_ret = np.log(monthly_quotes/monthly_quotes.shift(1))\n",
    "np.random.seed(42)\n",
    "num_pf = 1000\n",
    "all_weights = np.zeros((num_pf, len(monthly_quotes.columns)))\n",
    "ret_arr = np.zeros(num_pf)\n",
    "vol_arr = np.zeros(num_pf)\n",
    "sharpe_arr = np.zeros(num_pf)\n",
    "for pf in range(num_pf):\n",
    "    weights = np.array(np.random.random(len(df)))\n",
    "    weights = weights / np.sum(weights)\n",
    "    all_weights[pf,:] = weights\n",
    "    #ret_arr[pf] = np.sum(weights * 12 * log_ret.mean())\n",
    "    ret_arr[pf] = np.sum(weights * GeoMeanReturn(log_ret))\n",
    "    vol_arr[pf] = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov()*12, weights)))\n",
    "    sharpe_arr[pf] = ret_arr[pf] / vol_arr[pf]\n",
    "    # pf_ExpRet.append(returns)\n",
    "    # pf_std.append(volatility)\n",
    "    # pf_sharpe.append(sharpe)\n",
    "    # pf_weights.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------Optimize Portfolio------------------------\n",
    "print('Portfolio-Optimierung gestartet .....')\n",
    "\n",
    "Number_of_Opp_Sets = 6\n",
    "opt_frontier_x_Soll = np.linspace(vol_arr.min(), vol_arr.max(), Number_of_Opp_Sets)\n",
    "opt_frontier_x_Ist = []\n",
    "opt_frontier_y = []\n",
    "opt_frontier_weights = []\n",
    "opt_frontier_SR = []\n",
    "\n",
    "for Vola in opt_frontier_x_Soll:\n",
    "    cons1 = ({'type':'eq','fun':constraint_check_sum},\n",
    "            {'type':'eq','fun':lambda w:get_ret_vol_sr(w)[1] - Vola})\n",
    "    bounds = ((0,1),)*len(df)\n",
    "    init_guess = [df['Weights']]\n",
    "    opt_results = minimize(neg_sharpe,init_guess,method='SLSQP',bounds=bounds,constraints=cons1)\n",
    "    opt_frontier_x_Ist.append(pf_vol(df_cov, opt_results.x))\n",
    "    opt_frontier_weights.append(opt_results.x)\n",
    "    opt_frontier_y.append(ret(df['Return'], opt_results.x))\n",
    "    opt_frontier_SR.append(opt_results['fun']*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- MyPortfolio optimiert --------------------------------------------\n",
    "print('Portfolio wird optimiert....')\n",
    "\n",
    "Vola = port_vol\n",
    "cons1 = ({'type': 'eq', 'fun': constraint_check_sum},\n",
    "        {'type': 'eq', 'fun': lambda w: get_ret_vol_sr(w)[1] - Vola})\n",
    "bounds = ((0, 1),) * len(df)\n",
    "init_guess = [df['Weights']]\n",
    "opt_results = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons1)\n",
    "port_vol_opt = pf_vol(df_cov, opt_results.x)\n",
    "port_weights_opt = opt_results.x\n",
    "port_ExpRet_opt = ret(df['Return'], opt_results.x)\n",
    "#port_SR_opt = opt_results['fun'] * (-1)\n",
    "port_SR_opt = port_ExpRet_opt/port_vol_opt\n",
    "port_var_opt = pf_var(df_cov,opt_results.x)\n",
    "\n",
    "df.insert(loc=7,column='Weights [optimiert]',value=port_weights_opt)\n",
    "\n",
    "#print('OptVola: ', port_vol_opt, 'OptExpRet: ', port_ExpRet_opt, 'OptSR: ',port_SR_opt, '\\n')\n",
    "#print('OptWeights', port_weights_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- Max Sharpe Ratio Portfolio ------------------------------------\n",
    "\n",
    "max_sr_ret = ret_arr[sharpe_arr.argmax()]\n",
    "max_sr_vol = vol_arr[sharpe_arr.argmax()]\n",
    "max_sr_weights = all_weights[sharpe_arr.argmax()]\n",
    "max_sr_var = max_sr_vol**2\n",
    "max_sr_SR = sharpe_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- Table MaxReturn for each Volatility Value --------------------------\n",
    "\n",
    "df_tbl_MaxRet = pd.DataFrame(list(zip(opt_frontier_x_Ist, opt_frontier_y, opt_frontier_SR)),columns=['Volatility', 'Expected Return', 'Sharpe Ratio'])\n",
    "df_frontier_weights = pd.DataFrame(opt_frontier_weights, columns=col_names)\n",
    "#df_tbl_MaxRet = pd.concat([df_tbl_MaxRet, df_frontier_weights], sort=False, axis=1)\n",
    "df_tbl_MaxRet_transposed = df_tbl_MaxRet.T\n",
    "df_frontier_weights_transposed = df_frontier_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----via XLSXwriter-----------\n",
    "\n",
    "today = str(dt.date.today())\n",
    "writer = pd.ExcelWriter('Output_' + today + '.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# -----set wb as variable------------\n",
    "\n",
    "wb = writer.book\n",
    "\n",
    "# -----formats as variables-------------\n",
    "\n",
    "money_format = wb.add_format({'num_format': '#,##0.00', 'valign': 'center'})\n",
    "percent_format_1 = wb.add_format({'num_format': '#0.00%', 'valign': 'center'})\n",
    "percent_format_2 = wb.add_format({'bold':True,'num_format': '#0.00%'})\n",
    "\n",
    "header_format_1 = wb.add_format({'bold': True, 'text_wrap': True, 'valign': 'center', 'border': 0})\n",
    "header_format_2 = wb.add_format({'bold': True, 'text_wrap': True, 'valign': 'left', 'border': 0})\n",
    "border_format = wb.add_format({'border': 1})\n",
    "\n",
    "date_format_1 = wb.add_format({'num_format': 'dd/mm/yyyy'})\n",
    "date_format_2 = wb.add_format({'num_format': 'd mmm yyyy'})\n",
    "date_format_3 = wb.add_format({'num_format': 'dd.mm.yyyy'})\n",
    "\n",
    "text_format_1 = wb.add_format({'valign': 'left'})\n",
    "text_format_2 = wb.add_format({'valign': 'center'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----write DataFrames to sheets-------\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(writer, sheet_name='Assets', float_format=\"%.6f\", index=False, header=False, startrow=1)\n",
    "dummy_df.to_excel(writer, sheet_name='Portfolio Statistics', float_format=\"%.6f\", startcol=1, startrow=1,\n",
    "                index=False, header=False)\n",
    "df_corr.to_excel(writer, sheet_name='Correlation Matrix', float_format=\"%.6f\", startcol=1, startrow=1,\n",
    "                index=False, header=False)\n",
    "monthly_quotes_data.to_excel(writer, sheet_name='Data', float_format=\"%.6f\", index=False, header=False,\n",
    "                        startrow=1, startcol=1)\n",
    "df_tbl_MaxRet_transposed.to_excel(writer, sheet_name='Portfolio Statistics', float_format=\"%.3f\", index=False, header=False,\n",
    "                        startrow=35, startcol=5)\n",
    "df_frontier_weights_transposed.to_excel(writer, sheet_name='Portfolio Statistics', float_format=\"%.3f\", index=False, header=False,\n",
    "                        startrow=41, startcol=5)\n",
    "\n",
    "# ------assign worksheets to variables-------------\n",
    "\n",
    "ws1 = writer.sheets['Assets']\n",
    "ws2 = writer.sheets['Portfolio Statistics']\n",
    "ws3 = writer.sheets['Data']\n",
    "ws4 = writer.sheets['Correlation Matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----write headers & index-------------------\n",
    "\n",
    "for col_num, value in enumerate(df.columns.values):\n",
    "    ws1.write(0, col_num, value, header_format_1)\n",
    "\n",
    "for col_num, value in enumerate(df_corr.columns.values):\n",
    "    ws4.write(0, col_num + 1, value, text_format_2)\n",
    "\n",
    "for row_num, value in enumerate(df_corr.columns.values):\n",
    "    ws4.write(row_num + 1, 0, value, text_format_1)\n",
    "\n",
    "col_names_inkl_CCY = col_names.tolist() + currencies.to_list()\n",
    "for col_num, value in enumerate(col_names_inkl_CCY):\n",
    "    ws3.write(0, col_num + 1, value, header_format_1)\n",
    "\n",
    "for row_num, value in enumerate(monthly_quotes.index):\n",
    "    ws3.write(row_num + 1, 0, value, date_format_1)\n",
    "\n",
    "for row_num, value in enumerate(df_tbl_MaxRet.columns.values):\n",
    "    ws2.write(row_num + 35, 4, value, header_format_2)\n",
    "for row_num, value in enumerate(df_frontier_weights.columns.values):\n",
    "    ws2.write(row_num + 41, 4, value, text_format_1)\n",
    "\n",
    "for i in range(1,Number_of_Opp_Sets+1):\n",
    "    ws2.write(34, 4+i,'Opportunity Set ' + str(i),header_format_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------write Portfolio Statistics to Portfolio Sheet----------\n",
    "\n",
    "\n",
    "\n",
    "ws2.set_comments_author('Andreas Eirich')\n",
    "author = 'Andreas Eirich'\n",
    "\n",
    "ws2.write('A1', 'PORTFOLIO [AKTUELL]:', header_format_2)\n",
    "\n",
    "ws2.write('A3', 'Expected Return:')\n",
    "ws2.write('B3', Exp, percent_format_1)\n",
    "#ws2.write_comment('B3','ACHTUNG: Währungskomponente z.B. USD/EUR aktuell noch nicht berücksichtigt')\n",
    "\n",
    "ws2.write('A4', 'Portfolio Variance:')\n",
    "ws2.write('B4', port_var, percent_format_1)\n",
    "\n",
    "ws2.write('A5', 'Portfolio Standard Deviation:')\n",
    "ws2.write('B5', port_vol, percent_format_1)\n",
    "\n",
    "ws2.write('A6', 'Sharpe Ratio [ohne Berücksichtigung von rf]:')\n",
    "ws2.write('B6', Exp / port_vol, money_format)\n",
    "\n",
    "ws2.write ('A8', 'PORTFOLIO [OPTIMIERT]:', header_format_2)\n",
    "\n",
    "ws2.write('A10', 'Expected Return:')\n",
    "ws2.write('B10', port_ExpRet_opt, percent_format_1)\n",
    "ws2.write_comment('B10','DISCLAIMER: Historische Wertentwicklungen in der Vergangenheit sind kein verlässlicher Indikator für die künftige Wertentwicklung.',\n",
    "                {'x_scale': 2})\n",
    "\n",
    "ws2.write('A11', 'Portfolio Variance:')\n",
    "ws2.write('B11', port_var_opt, percent_format_1)\n",
    "\n",
    "ws2.write('A12', 'Portfolio Standard Deviation:')\n",
    "ws2.write('B12', port_vol_opt, percent_format_1)\n",
    "\n",
    "ws2.write('A13', 'Sharpe Ratio [ohne Berücksichtigung von rf]:')\n",
    "ws2.write('B13', port_SR_opt, money_format)\n",
    "\n",
    "ws2.write ('A15', 'PORTFOLIO [MAX SHARPE RATIO]:', header_format_2)\n",
    "\n",
    "ws2.write('A17', 'Expected Return:')\n",
    "ws2.write('B17', max_sr_ret, percent_format_1)\n",
    "\n",
    "ws2.write('A18', 'Portfolio Variance:')\n",
    "ws2.write('B18', max_sr_var, percent_format_1)\n",
    "\n",
    "ws2.write('A19', 'Portfolio Standard Deviation:')\n",
    "ws2.write('B19', max_sr_vol, percent_format_1)\n",
    "\n",
    "ws2.write('A20', 'Sharpe Ratio [ohne Berücksichtigung von rf]:')\n",
    "ws2.write('B20', max_sr_SR, money_format)\n",
    "\n",
    "ws2.write('G40', '---------------------------------- PORTFOLIO GEWICHTUNGEN ----------------------------------', text_format_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Graph Efficient Frontier Linie -----------------\n",
    "\n",
    "frontier_y = np.linspace(0.05,0.3,5) #todo Wert 20 erhöhen, vorher: 200\n",
    "\n",
    "\n",
    "frontier_x = []\n",
    "frontier_weights = []\n",
    "\n",
    "for possible_return in frontier_y:\n",
    "    cons2 = ({'type':'eq','fun':constraint_check_sum},\n",
    "            {'type':'eq','fun':lambda w:get_ret_vol_sr(w)[0] - possible_return})\n",
    "    result = minimize(minimize_volatility,init_guess,method='SLSQP',bounds=bounds,constraints=cons2)\n",
    "    frontier_x.append(result['fun'])\n",
    "\n",
    "\n",
    "#print('Vola: ', pf_vol(df_cov,w_min))\n",
    "#print('ExpRet: ', ret(df['Return'],w_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Plot Efficient Frontier--------------------\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(x=vol_arr, y=ret_arr, c=sharpe_arr, cmap='inferno') #for different color scales see: https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html\n",
    "plt.colorbar(label='Sharpe ratio')\n",
    "sns.set(style='darkgrid')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.scatter(max_sr_vol, max_sr_ret, c='purple',s=50) #portfolio max Sharpe ratio\n",
    "plt.annotate(text='Portfolio with highest SR',xy=(max_sr_vol,max_sr_ret),xytext=(7,0),textcoords='offset points',ha='left',va='center')\n",
    "plt.plot(frontier_x,frontier_y,'r--',linewidth=3) #frontier line\n",
    "plt.scatter(port_vol, Exp, c='red',s=50) # current portfolio\n",
    "plt.annotate(text='Current Portfolio',xy=(port_vol,Exp),xytext=(7,0),textcoords='offset points',ha='left',va='center')\n",
    "plt.scatter(port_vol_opt, port_ExpRet_opt, c='blue',s=50) # Optimized portfolio\n",
    "plt.annotate(text='Optimized Portfolio',xy=(port_vol_opt,port_ExpRet_opt),xytext=(7,0),textcoords='offset points',ha='left',va='center')\n",
    "\n",
    "imgdata2 = BytesIO()\n",
    "plt.savefig(imgdata2, format=\"png\", transparent=True)\n",
    "imgdata2.seek(0)\n",
    "ws2.insert_image(0, 2, \"\", {'image_data': imgdata2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----formatting--------------------\n",
    "\n",
    "ws1.set_zoom(90)\n",
    "ws2.set_zoom(85)\n",
    "ws3.set_zoom(110)\n",
    "ws4.set_zoom(110)\n",
    "\n",
    "ws1.hide_gridlines(2)\n",
    "ws2.hide_gridlines(2)\n",
    "ws3.hide_gridlines(2)\n",
    "ws4.hide_gridlines(2)\n",
    "\n",
    "ws1.set_column('A:E', 25, text_format_1)\n",
    "ws1.set_column('F:F', 40, money_format)\n",
    "ws1.set_column('G:J', 25, percent_format_1)\n",
    "ws1.set_column('K:M', 40, money_format)\n",
    "ws1.set_column('B:B', 45, text_format_1)\n",
    "ws1.set_column('L:L', 25, date_format_1)\n",
    "\n",
    "ws2.set_column('A:A', 40)\n",
    "ws2.set_column('B:B', 25)\n",
    "ws2.set_column('C:C', 0.5)\n",
    "ws2.set_column('D:AAA', 20, percent_format_1)\n",
    "ws2.set_row(37,None,money_format)\n",
    "\n",
    "\n",
    "ws3.set_column('B:AAA', 25, money_format)\n",
    "ws3.set_column('A:A', 11)\n",
    "ws3.freeze_panes(1, 0)\n",
    "\n",
    "ws4.set_column('A:AAA', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Bar Chart Asset Sharpe Ratios-------------\n",
    "\n",
    "length_df = str(len(df) + 1)\n",
    "\n",
    "chart = wb.add_chart({'type': 'column'})\n",
    "\n",
    "chart.add_series({\n",
    "    'values': '=Assets!$I$2:$I$' + length_df,\n",
    "    'categories': '=Assets!$E$2:$E$' + length_df,\n",
    "    'fill': {'color': '#FF9900'}\n",
    "})\n",
    "\n",
    "chart.set_y_axis({'name': '=Assets!I1'})\n",
    "chart.set_x_axis({'name': 'Assets'})\n",
    "chart.set_legend({'none': True})\n",
    "chart.set_size({'x_scale': 2, 'y_scale': 1.5})\n",
    "\n",
    "ws1.insert_chart('O2', chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Pie Chart Asset Allocation Current Portfolio-------\n",
    "df_group = df[['Asset Class','Weights']]\n",
    "df_group = df_group.groupby(df['Asset Class']).sum()\n",
    "pie_plot = df_group.plot.pie(y='Weights',figsize=(5,5), autopct='%1.1f%%', legend=False, label='Current Portfolio')\n",
    "\n",
    "#pie_plot.legend(loc='upper left')\n",
    "imgdata5 = BytesIO()\n",
    "pie_plot.figure.savefig(imgdata5,format='png',transparent=True)\n",
    "imgdata5.seek(0)\n",
    "ws2.insert_image('A25', \"\", {'image_data': imgdata5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Pie Chart Asset Allocation Optimized Portfolio-------\n",
    "\n",
    "df_group = df[['Asset Class','Weights [optimiert]']]\n",
    "df_group = df_group.groupby(df['Asset Class']).sum()\n",
    "pie_plot = df_group.plot.pie(y='Weights [optimiert]',figsize=(5,5), autopct='%1.1f%%', legend=False, label='Optimized Portfolio')\n",
    "\n",
    "#pie_plot.legend(loc='upper left')\n",
    "imgdata6 = BytesIO()\n",
    "pie_plot.figure.savefig(imgdata6,format='png',transparent=True)\n",
    "imgdata6.seek(0)\n",
    "ws2.insert_image('A47', \"\", {'image_data': imgdata6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Graph Historic Returns--------------------------\n",
    "\n",
    "plt.figure(figsize=(12,len(col_names)*2))\n",
    "# for c, i in enumerate(quotes.columns.values):\n",
    "#     plt.plot(quotes[i],label=col_names[c])\n",
    "#quotes.insert(loc=0,column='Composite Prices',value=df_MyPortfolio)\n",
    "quotes.columns=col_names\n",
    "quotes.plot(title=\"Historic Prices\", figsize=(12,len(col_names)*2),subplots=True)\n",
    "#plt.title('Historic prices')\n",
    "plt.xlabel('Date',fontsize=13)\n",
    "plt.ylabel('Prices',fontsize=13)\n",
    "plt.legend(loc='upper left', borderaxespad=1)\n",
    "imgdata1 = BytesIO()\n",
    "plt.savefig(imgdata1, format=\"png\", transparent=True)\n",
    "imgdata1.seek(0)\n",
    "ws1.insert_image('N25', \"\", {'image_data': imgdata1})\n",
    "\n",
    "#df_MyPortfolio = df_MyPortfolio.cumsum()\n",
    "#df_MyPortfolio.plot(x='CompositeReturn',title=\"Strategies Returns\", figsize=(12,10),subplots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Performance Measurement -----------------------------\n",
    "\n",
    "\n",
    "pyfolio.tears.create_returns_tear_sheet(pd.Series(df_MyPortfolio_returns['CompositeReturn']))\n",
    "#pyfolio.create_full_tear_sheet(pd.Series(df_MyPortfolio_returns['CompositeReturn']))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "imgdata3 = BytesIO()\n",
    "plt.savefig(imgdata3, format=\"png\", transparent=True)\n",
    "imgdata3.seek(0)\n",
    "ws2.insert_image(0, 15, \"\", {'image_data': imgdata3})\n",
    "\n",
    "\n",
    "col_names = np.insert(col_names,0,'CompositeReturn',axis=0)\n",
    "df_MyPortfolio_returns.columns=col_names\n",
    "df_MyPortfolio_returns.plot(kind='hist',bins=15,subplots=True,figsize=(16,10))\n",
    "\n",
    "imgdata4 = BytesIO()\n",
    "plt.savefig(imgdata4, format=\"png\", transparent=True)\n",
    "imgdata4.seek(0)\n",
    "ws1.insert_image(0, 40, \"\", {'image_data': imgdata4})\n",
    "\n",
    "\n",
    "\n",
    "writer.save()\n",
    "writer.close()\n",
    "print('Vorgang abgeschlossen')\n",
    "ende=time.time()\n",
    "print('Dauer Programmablauf: ','{:5.3f} min'.format((ende-start)/60),end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

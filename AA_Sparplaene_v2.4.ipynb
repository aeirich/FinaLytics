{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from AE_Functions import *\n",
    "from pandas import *\n",
    "from io import BytesIO\n",
    "import time\n",
    "import sys\n",
    "from forex_python.converter import CurrencyRates\n",
    "from scipy.optimize import minimize\n",
    "#import pyfolio\n",
    "import numpy as np\n",
    "#from nbconvert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "def GeoMeanReturn(pct_change_column):\n",
    "    return (((1 + pct_change_column).product()) ** (1 / (len(pct_change_column))) - 1) * 12\n",
    "\n",
    "def ret(returns, weights):\n",
    "    return returns.dot(weights)\n",
    "\n",
    "def pf_var(covar,weights):\n",
    "    return np.dot(weights,np.dot(weights,covar))\n",
    "\n",
    "def pf_vol(covar,weights):\n",
    "    return np.sqrt(np.dot(weights,np.dot(weights,covar)))\n",
    "\n",
    "def get_ret_vol_sr(weights):\n",
    "    weights = np.array(weights)\n",
    "    #ret = np.sum(log_ret.mean() * weights) * 12\n",
    "    ret = np.sum(GeoMeanReturn(log_ret) * weights)\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov() * 12, weights)))\n",
    "    sr = ret / vol\n",
    "    return np.array([ret, vol, sr])\n",
    "\n",
    "\n",
    "def neg_sharpe(weights):\n",
    "    return get_ret_vol_sr(weights)[2] * -1\n",
    "\n",
    "\n",
    "def constraint_check_sum(weights):\n",
    "    return np.sum(weights) - 1\n",
    "\n",
    "def constraint_vola(weights, Vola):\n",
    "    return get_ret_vol_sr(weights)[1]\n",
    "\n",
    "def minimize_volatility(weights):\n",
    "    return get_ret_vol_sr(weights)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pandas requires version '3.1.0' or newer of 'openpyxl' (version '3.0.10' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e95b963ada1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbeg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2010\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m         io = ExcelFile(\n\u001b[0m\u001b[0;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m         self._reader = self._engines[engine](\n\u001b[0m\u001b[0;32m   1568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\excel\\_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0mArbitrary\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mexcel\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \"\"\"\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"openpyxl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         super().__init__(\n\u001b[0;32m    554\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Pandas requires version '3.1.0' or newer of 'openpyxl' (version '3.0.10' currently installed)."
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_excel('Input.xlsx')\n",
    "\n",
    "beg=(2010,1,1)\n",
    "end=(2022,12,31)\n",
    "\n",
    "ticker = (df['Ticker'].values)\n",
    "col_names = (df['Name'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------Tab Data---------------------------\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "quotes = pd.DataFrame()\n",
    "tmp_min_dates = pd.DataFrame()\n",
    "min_dates=[]\n",
    "\n",
    "print('Daten werden heruntergeladen und aufbereitet....')\n",
    "\n",
    "for i in ticker:\n",
    "    try:\n",
    "\n",
    "        quotes.insert(loc=len(quotes.columns), column=i, value=getQuote(i, beg, end, '1d'))\n",
    "        tmp_min_dates=quotes\n",
    "        min_dates.append(tmp_min_dates.index.min().to_pydatetime().date())\n",
    "        quotes.dropna(inplace=True)\n",
    "        # monthly_quotes=quotes.resample('M').agg(lambda x: x[-1])\n",
    "        monthly_quotes_ForCCY = quotes.resample('BM').last()\n",
    "    except Exception as err:\n",
    "        print('Error: ', err)\n",
    "        print('Security: ', i)\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "print('Daten verfügbar....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- Download Währungen --------------------------------\n",
    "from currency_converter import CurrencyConverter\n",
    "from datetime import timedelta\n",
    "currencies = df['Currency'].drop_duplicates()\n",
    "c = CurrencyConverter()\n",
    "df_CCY = pd.DataFrame()\n",
    "for ccy in currencies:\n",
    "    fx_rates = []\n",
    "    for day in monthly_quotes_ForCCY.index.date:\n",
    "        try:\n",
    "            x = c.convert(1,'EUR',ccy,day)\n",
    "            fx_rates.append(x)\n",
    "        except:\n",
    "            dayminusone=day-timedelta(days=1)\n",
    "            x = c.convert(1,'EUR',ccy,dayminusone)\n",
    "            fx_rates.append(x)\n",
    "            continue\n",
    "    fx_rates_ = pd.Series(fx_rates, index=monthly_quotes_ForCCY.index.date)\n",
    "    df_CCY.insert(loc=len(df_CCY.columns),column=ccy,value=fx_rates)\n",
    "\n",
    "df_CCY.index=monthly_quotes_ForCCY.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Calculate Domestic Return ----------------------\n",
    "monthly_quotes = pd.DataFrame()\n",
    "monthly_quotes_data = monthly_quotes_ForCCY.join(df_CCY,how='outer')\n",
    "for i in ticker:\n",
    "    ccy = (df.loc[df['Ticker']==i,['Currency']].values)[0][0]\n",
    "    monthly_quotes[str(i)] = monthly_quotes_data[i]/monthly_quotes_data[ccy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------Tab Assets----------------\n",
    "\n",
    "print('Worksheet Assets wird vorbereitet....')\n",
    "\n",
    "#Performance = monthly_quotes.pct_change().dropna()\n",
    "Performance = np.log(monthly_quotes/monthly_quotes.shift(1)).dropna()\n",
    "#MeanReturn = (((1 + Performance).product()) ** (1 / (len(Performance) - 1)) - 1) * 12\n",
    "MeanReturn = GeoMeanReturn(Performance)\n",
    "vola = Performance.std() * np.sqrt(12)\n",
    "cov = Performance.cov() * 12\n",
    "\n",
    "\n",
    "\n",
    "list_ret = []\n",
    "vol = []\n",
    "\n",
    "for i in MeanReturn.values:\n",
    "    list_ret.append(i)\n",
    "\n",
    "for i in vola.values:\n",
    "    vol.append(i)\n",
    "\n",
    "weights = df['Wert in EUR/Sparrate'] / df['Wert in EUR/Sparrate'].sum()\n",
    "\n",
    "df.insert(loc=6, column='Weights', value=weights)\n",
    "df.insert(loc=7, column='Return', value=list_ret)\n",
    "df.insert(loc=8, column='Standard Deviation', value=vol)\n",
    "df.insert(loc=9, column='Sharpe Ratio [ohne Berücksichtigung von rf]',\n",
    "        value=df['Return'] / df['Standard Deviation'])\n",
    "df.insert(loc=10, column='Earliest Datapoint', value=min_dates)\n",
    "\n",
    "df_MyPortfolio = monthly_quotes\n",
    "df_MyPortfolio_returns = np.log(monthly_quotes/monthly_quotes.shift(1)).dropna()\n",
    "#df_MyPortfolio_returns = df_MyPortfolio.pct_change().dropna()\n",
    "\n",
    "#df_MyPortfolio.insert(loc=0,column=col_names, value=quotes)\n",
    "#print(df_MyPortfolio_returns)\n",
    "\n",
    "for i,w in enumerate(weights):\n",
    "    df_MyPortfolio_returns.iloc[:,i] = df_MyPortfolio_returns.iloc[:,i] * w\n",
    "\n",
    "    \n",
    "df_MyPortfolio_returns.insert(loc=0,column='CompositeReturn',value=df_MyPortfolio_returns.sum(axis=1))\n",
    "\n",
    "\n",
    "for i,w in enumerate(weights):\n",
    "    df_MyPortfolio_returns.iloc[:,i+1] = df_MyPortfolio_returns.iloc[:,i+1] / w\n",
    "\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------Correlation Matrix------\n",
    "print('Worksheet Correlation Matrix wird vorbereitet....')\n",
    "\n",
    "df_corr = pd.DataFrame()\n",
    "df_cov = pd.DataFrame()\n",
    "dummy_df = pd.DataFrame()\n",
    "\n",
    "for i in ticker:\n",
    "    try:\n",
    "        price = getQuote(i, beg, end, '1d')\n",
    "        price = price.ffill()\n",
    "        monthly_prices = price.resample('BM').last()  # filtert den letzten Tag im Monat // BM = Business Month // Alternative: 1ter Tag im Monat ('BMS').first() // BMS = Business Month Start\n",
    "        #perf = monthly_prices.pct_change()\n",
    "        perf = np.log(monthly_prices/monthly_prices.shift(1))\n",
    "        df_corr.insert(loc=len(df_corr.columns), column=i, value=perf)\n",
    "        df_cov.insert(loc=len(df_cov.columns), column=i, value=perf)\n",
    "    except Exception as err:\n",
    "        print('Error: ', err)\n",
    "        print('Security: ', i)\n",
    "        sys.exit(0)\n",
    "\n",
    "df_corr.columns = col_names\n",
    "\n",
    "df_corr.dropna(inplace=True)\n",
    "df_corr = df_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------Tab Portfolio Statistics-------------\n",
    "print('Worksheet Portfolio Statistics wird vorbereitet....')\n",
    "\n",
    "##------------Expected Return----------\n",
    "\n",
    "\n",
    "#Exp = df['Return'] * df['Weights']\n",
    "#Exp = Exp.sum()\n",
    "#Exp = ret(df['Return'].fillna(0),df['Weights'])\n",
    "Exp = ret(df['Return'],df['Weights'])\n",
    "\n",
    "\n",
    "\n",
    "##------------Standard Deviation-------\n",
    "\n",
    "df_cov.columns = col_names\n",
    "df_cov.dropna(inplace=True)\n",
    "df_cov = df_cov.cov() * 12\n",
    "\n",
    "#port_var = np.dot(df['Weights'].T, np.dot(df_cov, df['Weights']))\n",
    "#port_vol = np.sqrt(port_var)\n",
    "\n",
    "port_vol = pf_vol(df_cov,df['Weights'].T)\n",
    "port_var = pf_var(df_cov,df['Weights'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Efficient Frontier---------------------------\n",
    "print('Efficient Frontier wird vorbereitet....')\n",
    "\n",
    "\n",
    "log_ret = np.log(monthly_quotes/monthly_quotes.shift(1))\n",
    "np.random.seed(42)\n",
    "num_pf = 1000\n",
    "all_weights = np.zeros((num_pf, len(monthly_quotes.columns)))\n",
    "ret_arr = np.zeros(num_pf)\n",
    "vol_arr = np.zeros(num_pf)\n",
    "sharpe_arr = np.zeros(num_pf)\n",
    "for pf in range(num_pf):\n",
    "    weights = np.array(np.random.random(len(df)))\n",
    "    weights = weights / np.sum(weights)\n",
    "    all_weights[pf,:] = weights\n",
    "    #ret_arr[pf] = np.sum(weights * 12 * log_ret.mean())\n",
    "    ret_arr[pf] = np.sum(weights * GeoMeanReturn(log_ret))\n",
    "    vol_arr[pf] = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov()*12, weights)))\n",
    "    sharpe_arr[pf] = ret_arr[pf] / vol_arr[pf]\n",
    "    # pf_ExpRet.append(returns)\n",
    "    # pf_std.append(volatility)\n",
    "    # pf_sharpe.append(sharpe)\n",
    "    # pf_weights.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------Optimize Portfolio------------------------\n",
    "print('Portfolio-Optimierung gestartet .....')\n",
    "\n",
    "Number_of_Opp_Sets = 6\n",
    "opt_frontier_x_Soll = np.linspace(vol_arr.min(), vol_arr.max(), Number_of_Opp_Sets)\n",
    "opt_frontier_x_Ist = []\n",
    "opt_frontier_y = []\n",
    "opt_frontier_weights = []\n",
    "opt_frontier_SR = []\n",
    "\n",
    "for Vola in opt_frontier_x_Soll:\n",
    "    cons1 = ({'type':'eq','fun':constraint_check_sum},\n",
    "            {'type':'eq','fun':lambda w:get_ret_vol_sr(w)[1] - Vola})\n",
    "    bounds = ((0,1),)*len(df)\n",
    "    init_guess = [df['Weights']]\n",
    "    opt_results = minimize(neg_sharpe,init_guess,method='SLSQP',bounds=bounds,constraints=cons1)\n",
    "    opt_frontier_x_Ist.append(pf_vol(df_cov, opt_results.x))\n",
    "    opt_frontier_weights.append(opt_results.x)\n",
    "    opt_frontier_y.append(ret(df['Return'], opt_results.x))\n",
    "    opt_frontier_SR.append(opt_results['fun']*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- MyPortfolio optimiert --------------------------------------------\n",
    "print('Portfolio wird optimiert....')\n",
    "\n",
    "Vola = port_vol\n",
    "cons1 = ({'type': 'eq', 'fun': constraint_check_sum},\n",
    "        {'type': 'eq', 'fun': lambda w: get_ret_vol_sr(w)[1] - Vola})\n",
    "bounds = ((0, 1),) * len(df)\n",
    "init_guess = [df['Weights']]\n",
    "opt_results = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons1)\n",
    "port_vol_opt = pf_vol(df_cov, opt_results.x)\n",
    "port_weights_opt = opt_results.x\n",
    "port_ExpRet_opt = ret(df['Return'], opt_results.x)\n",
    "#port_SR_opt = opt_results['fun'] * (-1)\n",
    "port_SR_opt = port_ExpRet_opt/port_vol_opt\n",
    "port_var_opt = pf_var(df_cov,opt_results.x)\n",
    "\n",
    "df.insert(loc=7,column='Weights [optimiert]',value=port_weights_opt)\n",
    "\n",
    "#print('OptVola: ', port_vol_opt, 'OptExpRet: ', port_ExpRet_opt, 'OptSR: ',port_SR_opt, '\\n')\n",
    "#print('OptWeights', port_weights_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- Max Sharpe Ratio Portfolio ------------------------------------\n",
    "\n",
    "max_sr_ret = ret_arr[sharpe_arr.argmax()]\n",
    "max_sr_vol = vol_arr[sharpe_arr.argmax()]\n",
    "max_sr_weights = all_weights[sharpe_arr.argmax()]\n",
    "max_sr_var = max_sr_vol**2\n",
    "max_sr_SR = sharpe_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- Table MaxReturn for each Volatility Value --------------------------\n",
    "\n",
    "df_tbl_MaxRet = pd.DataFrame(list(zip(opt_frontier_x_Ist, opt_frontier_y, opt_frontier_SR)),columns=['Volatility', 'Expected Return', 'Sharpe Ratio'])\n",
    "df_frontier_weights = pd.DataFrame(opt_frontier_weights, columns=col_names)\n",
    "#df_tbl_MaxRet = pd.concat([df_tbl_MaxRet, df_frontier_weights], sort=False, axis=1)\n",
    "df_tbl_MaxRet_transposed = df_tbl_MaxRet.T\n",
    "df_frontier_weights_transposed = df_frontier_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----via XLSXwriter-----------\n",
    "\n",
    "today = str(dt.date.today())\n",
    "writer = pd.ExcelWriter('Output_' + today + '.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# -----set wb as variable------------\n",
    "\n",
    "wb = writer.book\n",
    "\n",
    "# -----formats as variables-------------\n",
    "\n",
    "money_format = wb.add_format({'num_format': '#,##0.00', 'valign': 'center'})\n",
    "percent_format_1 = wb.add_format({'num_format': '#0.00%', 'valign': 'center'})\n",
    "percent_format_2 = wb.add_format({'bold':True,'num_format': '#0.00%'})\n",
    "\n",
    "header_format_1 = wb.add_format({'bold': True, 'text_wrap': True, 'valign': 'center', 'border': 0})\n",
    "header_format_2 = wb.add_format({'bold': True, 'text_wrap': True, 'valign': 'left', 'border': 0})\n",
    "border_format = wb.add_format({'border': 1})\n",
    "\n",
    "date_format_1 = wb.add_format({'num_format': 'dd/mm/yyyy'})\n",
    "date_format_2 = wb.add_format({'num_format': 'd mmm yyyy'})\n",
    "date_format_3 = wb.add_format({'num_format': 'dd.mm.yyyy'})\n",
    "\n",
    "text_format_1 = wb.add_format({'valign': 'left'})\n",
    "text_format_2 = wb.add_format({'valign': 'center'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----write DataFrames to sheets-------\n",
    "\n",
    "\n",
    "\n",
    "df.to_excel(writer, sheet_name='Assets', float_format=\"%.6f\", index=False, header=False, startrow=1)\n",
    "dummy_df.to_excel(writer, sheet_name='Portfolio Statistics', float_format=\"%.6f\", startcol=1, startrow=1,\n",
    "                index=False, header=False)\n",
    "df_corr.to_excel(writer, sheet_name='Correlation Matrix', float_format=\"%.6f\", startcol=1, startrow=1,\n",
    "                index=False, header=False)\n",
    "monthly_quotes_data.to_excel(writer, sheet_name='Data', float_format=\"%.6f\", index=False, header=False,\n",
    "                        startrow=1, startcol=1)\n",
    "df_tbl_MaxRet_transposed.to_excel(writer, sheet_name='Portfolio Statistics', float_format=\"%.3f\", index=False, header=False,\n",
    "                        startrow=35, startcol=5)\n",
    "df_frontier_weights_transposed.to_excel(writer, sheet_name='Portfolio Statistics', float_format=\"%.3f\", index=False, header=False,\n",
    "                        startrow=41, startcol=5)\n",
    "\n",
    "# ------assign worksheets to variables-------------\n",
    "\n",
    "ws1 = writer.sheets['Assets']\n",
    "ws2 = writer.sheets['Portfolio Statistics']\n",
    "ws3 = writer.sheets['Data']\n",
    "ws4 = writer.sheets['Correlation Matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----write headers & index-------------------\n",
    "\n",
    "for col_num, value in enumerate(df.columns.values):\n",
    "    ws1.write(0, col_num, value, header_format_1)\n",
    "\n",
    "for col_num, value in enumerate(df_corr.columns.values):\n",
    "    ws4.write(0, col_num + 1, value, text_format_2)\n",
    "\n",
    "for row_num, value in enumerate(df_corr.columns.values):\n",
    "    ws4.write(row_num + 1, 0, value, text_format_1)\n",
    "\n",
    "col_names_inkl_CCY = col_names.tolist() + currencies.to_list()\n",
    "for col_num, value in enumerate(col_names_inkl_CCY):\n",
    "    ws3.write(0, col_num + 1, value, header_format_1)\n",
    "\n",
    "for row_num, value in enumerate(monthly_quotes.index):\n",
    "    ws3.write(row_num + 1, 0, value, date_format_1)\n",
    "\n",
    "for row_num, value in enumerate(df_tbl_MaxRet.columns.values):\n",
    "    ws2.write(row_num + 35, 4, value, header_format_2)\n",
    "for row_num, value in enumerate(df_frontier_weights.columns.values):\n",
    "    ws2.write(row_num + 41, 4, value, text_format_1)\n",
    "\n",
    "for i in range(1,Number_of_Opp_Sets+1):\n",
    "    ws2.write(34, 4+i,'Opportunity Set ' + str(i),header_format_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------write Portfolio Statistics to Portfolio Sheet----------\n",
    "\n",
    "\n",
    "\n",
    "ws2.set_comments_author('Andreas Eirich')\n",
    "author = 'Andreas Eirich'\n",
    "\n",
    "ws2.write('A1', 'PORTFOLIO [AKTUELL]:', header_format_2)\n",
    "\n",
    "ws2.write('A3', 'Expected Return:')\n",
    "ws2.write('B3', Exp, percent_format_1)\n",
    "#ws2.write_comment('B3','ACHTUNG: Währungskomponente z.B. USD/EUR aktuell noch nicht berücksichtigt')\n",
    "\n",
    "ws2.write('A4', 'Portfolio Variance:')\n",
    "ws2.write('B4', port_var, percent_format_1)\n",
    "\n",
    "ws2.write('A5', 'Portfolio Standard Deviation:')\n",
    "ws2.write('B5', port_vol, percent_format_1)\n",
    "\n",
    "ws2.write('A6', 'Sharpe Ratio [ohne Berücksichtigung von rf]:')\n",
    "ws2.write('B6', Exp / port_vol, money_format)\n",
    "\n",
    "ws2.write ('A8', 'PORTFOLIO [OPTIMIERT]:', header_format_2)\n",
    "\n",
    "ws2.write('A10', 'Expected Return:')\n",
    "ws2.write('B10', port_ExpRet_opt, percent_format_1)\n",
    "ws2.write_comment('B10','DISCLAIMER: Historische Wertentwicklungen in der Vergangenheit sind kein verlässlicher Indikator für die künftige Wertentwicklung.',\n",
    "                {'x_scale': 2})\n",
    "\n",
    "ws2.write('A11', 'Portfolio Variance:')\n",
    "ws2.write('B11', port_var_opt, percent_format_1)\n",
    "\n",
    "ws2.write('A12', 'Portfolio Standard Deviation:')\n",
    "ws2.write('B12', port_vol_opt, percent_format_1)\n",
    "\n",
    "ws2.write('A13', 'Sharpe Ratio [ohne Berücksichtigung von rf]:')\n",
    "ws2.write('B13', port_SR_opt, money_format)\n",
    "\n",
    "ws2.write ('A15', 'PORTFOLIO [MAX SHARPE RATIO]:', header_format_2)\n",
    "\n",
    "ws2.write('A17', 'Expected Return:')\n",
    "ws2.write('B17', max_sr_ret, percent_format_1)\n",
    "\n",
    "ws2.write('A18', 'Portfolio Variance:')\n",
    "ws2.write('B18', max_sr_var, percent_format_1)\n",
    "\n",
    "ws2.write('A19', 'Portfolio Standard Deviation:')\n",
    "ws2.write('B19', max_sr_vol, percent_format_1)\n",
    "\n",
    "ws2.write('A20', 'Sharpe Ratio [ohne Berücksichtigung von rf]:')\n",
    "ws2.write('B20', max_sr_SR, money_format)\n",
    "\n",
    "ws2.write('G40', '---------------------------------- PORTFOLIO GEWICHTUNGEN ----------------------------------', text_format_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Graph Efficient Frontier Linie -----------------\n",
    "\n",
    "frontier_y = np.linspace(0.05,0.3,5) #todo Wert 20 erhöhen, vorher: 200\n",
    "\n",
    "\n",
    "frontier_x = []\n",
    "frontier_weights = []\n",
    "\n",
    "for possible_return in frontier_y:\n",
    "    cons2 = ({'type':'eq','fun':constraint_check_sum},\n",
    "            {'type':'eq','fun':lambda w:get_ret_vol_sr(w)[0] - possible_return})\n",
    "    result = minimize(minimize_volatility,init_guess,method='SLSQP',bounds=bounds,constraints=cons2)\n",
    "    frontier_x.append(result['fun'])\n",
    "\n",
    "\n",
    "#print('Vola: ', pf_vol(df_cov,w_min))\n",
    "#print('ExpRet: ', ret(df['Return'],w_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Plot Efficient Frontier--------------------\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.scatter(x=vol_arr, y=ret_arr, c=sharpe_arr, cmap='inferno') #for different color scales see: https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html\n",
    "plt.colorbar(label='Sharpe ratio')\n",
    "sns.set(style='darkgrid')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.scatter(max_sr_vol, max_sr_ret, c='purple',s=50) #portfolio max Sharpe ratio\n",
    "plt.annotate(text='Portfolio with highest SR',xy=(max_sr_vol,max_sr_ret),xytext=(7,0),textcoords='offset points',ha='left',va='center')\n",
    "plt.plot(frontier_x,frontier_y,'r--',linewidth=3) #frontier line\n",
    "plt.scatter(port_vol, Exp, c='red',s=50) # current portfolio\n",
    "plt.annotate(text='Current Portfolio',xy=(port_vol,Exp),xytext=(7,0),textcoords='offset points',ha='left',va='center')\n",
    "plt.scatter(port_vol_opt, port_ExpRet_opt, c='blue',s=50) # Optimized portfolio\n",
    "plt.annotate(text='Optimized Portfolio',xy=(port_vol_opt,port_ExpRet_opt),xytext=(7,0),textcoords='offset points',ha='left',va='center')\n",
    "\n",
    "imgdata2 = BytesIO()\n",
    "plt.savefig(imgdata2, format=\"png\", transparent=True)\n",
    "imgdata2.seek(0)\n",
    "ws2.insert_image(0, 2, \"\", {'image_data': imgdata2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----formatting--------------------\n",
    "\n",
    "ws1.set_zoom(90)\n",
    "ws2.set_zoom(85)\n",
    "ws3.set_zoom(110)\n",
    "ws4.set_zoom(110)\n",
    "\n",
    "ws1.hide_gridlines(2)\n",
    "ws2.hide_gridlines(2)\n",
    "ws3.hide_gridlines(2)\n",
    "ws4.hide_gridlines(2)\n",
    "\n",
    "ws1.set_column('A:E', 25, text_format_1)\n",
    "ws1.set_column('F:F', 40, money_format)\n",
    "ws1.set_column('G:J', 25, percent_format_1)\n",
    "ws1.set_column('K:M', 40, money_format)\n",
    "ws1.set_column('B:B', 45, text_format_1)\n",
    "ws1.set_column('L:L', 25, date_format_1)\n",
    "\n",
    "ws2.set_column('A:A', 40)\n",
    "ws2.set_column('B:B', 25)\n",
    "ws2.set_column('C:C', 0.5)\n",
    "ws2.set_column('D:AAA', 20, percent_format_1)\n",
    "ws2.set_row(37,None,money_format)\n",
    "\n",
    "\n",
    "ws3.set_column('B:AAA', 25, money_format)\n",
    "ws3.set_column('A:A', 11)\n",
    "ws3.freeze_panes(1, 0)\n",
    "\n",
    "ws4.set_column('A:AAA', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Bar Chart Asset Sharpe Ratios-------------\n",
    "\n",
    "length_df = str(len(df) + 1)\n",
    "\n",
    "chart = wb.add_chart({'type': 'column'})\n",
    "\n",
    "chart.add_series({\n",
    "    'values': '=Assets!$I$2:$I$' + length_df,\n",
    "    'categories': '=Assets!$E$2:$E$' + length_df,\n",
    "    'fill': {'color': '#FF9900'}\n",
    "})\n",
    "\n",
    "chart.set_y_axis({'name': '=Assets!I1'})\n",
    "chart.set_x_axis({'name': 'Assets'})\n",
    "chart.set_legend({'none': True})\n",
    "chart.set_size({'x_scale': 2, 'y_scale': 1.5})\n",
    "\n",
    "ws1.insert_chart('O2', chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Pie Chart Asset Allocation Current Portfolio-------\n",
    "df_group = df[['Asset Class','Weights']]\n",
    "df_group = df_group.groupby(df['Asset Class']).sum()\n",
    "pie_plot = df_group.plot.pie(y='Weights',figsize=(5,5), autopct='%1.1f%%', legend=False, label='Current Portfolio')\n",
    "\n",
    "#pie_plot.legend(loc='upper left')\n",
    "imgdata5 = BytesIO()\n",
    "pie_plot.figure.savefig(imgdata5,format='png',transparent=True)\n",
    "imgdata5.seek(0)\n",
    "ws2.insert_image('A25', \"\", {'image_data': imgdata5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Pie Chart Asset Allocation Optimized Portfolio-------\n",
    "\n",
    "df_group = df[['Asset Class','Weights [optimiert]']]\n",
    "df_group = df_group.groupby(df['Asset Class']).sum()\n",
    "pie_plot = df_group.plot.pie(y='Weights [optimiert]',figsize=(5,5), autopct='%1.1f%%', legend=False, label='Optimized Portfolio')\n",
    "\n",
    "#pie_plot.legend(loc='upper left')\n",
    "imgdata6 = BytesIO()\n",
    "pie_plot.figure.savefig(imgdata6,format='png',transparent=True)\n",
    "imgdata6.seek(0)\n",
    "ws2.insert_image('A47', \"\", {'image_data': imgdata6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Graph Historic Returns--------------------------\n",
    "\n",
    "plt.figure(figsize=(12,len(col_names)*2))\n",
    "# for c, i in enumerate(quotes.columns.values):\n",
    "#     plt.plot(quotes[i],label=col_names[c])\n",
    "#quotes.insert(loc=0,column='Composite Prices',value=df_MyPortfolio)\n",
    "quotes.columns=col_names\n",
    "quotes.plot(title=\"Historic Prices\", figsize=(12,len(col_names)*2),subplots=True)\n",
    "#plt.title('Historic prices')\n",
    "plt.xlabel('Date',fontsize=13)\n",
    "plt.ylabel('Prices',fontsize=13)\n",
    "plt.legend(loc='upper left', borderaxespad=1)\n",
    "imgdata1 = BytesIO()\n",
    "plt.savefig(imgdata1, format=\"png\", transparent=True)\n",
    "imgdata1.seek(0)\n",
    "ws1.insert_image('N25', \"\", {'image_data': imgdata1})\n",
    "\n",
    "#df_MyPortfolio = df_MyPortfolio.cumsum()\n",
    "#df_MyPortfolio.plot(x='CompositeReturn',title=\"Strategies Returns\", figsize=(12,10),subplots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Performance Measurement -----------------------------\n",
    "\n",
    "\n",
    "pyfolio.tears.create_returns_tear_sheet(pd.Series(df_MyPortfolio_returns['CompositeReturn']))\n",
    "#pyfolio.create_full_tear_sheet(pd.Series(df_MyPortfolio_returns['CompositeReturn']))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "imgdata3 = BytesIO()\n",
    "plt.savefig(imgdata3, format=\"png\", transparent=True)\n",
    "imgdata3.seek(0)\n",
    "ws2.insert_image(0, 15, \"\", {'image_data': imgdata3})\n",
    "\n",
    "\n",
    "col_names = np.insert(col_names,0,'CompositeReturn',axis=0)\n",
    "df_MyPortfolio_returns.columns=col_names\n",
    "df_MyPortfolio_returns.plot(kind='hist',bins=15,subplots=True,figsize=(16,10))\n",
    "\n",
    "imgdata4 = BytesIO()\n",
    "plt.savefig(imgdata4, format=\"png\", transparent=True)\n",
    "imgdata4.seek(0)\n",
    "ws1.insert_image(0, 40, \"\", {'image_data': imgdata4})\n",
    "\n",
    "\n",
    "\n",
    "writer.save()\n",
    "writer.close()\n",
    "print('Vorgang abgeschlossen')\n",
    "ende=time.time()\n",
    "print('Dauer Programmablauf: ','{:5.3f} min'.format((ende-start)/60),end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
